services:
  opensearch:
    image: opensearchproject/opensearch:2.19.0
    labels:
      kompose.service.type: ClusterIP
      kompose.volume.size: 1Gi
    ports:
      - 9200:9200
    environment:
      - discovery.type=single-node
      - bootstrap.memory_lock=true
      - "OPENSEARCH_JAVA_OPTS=${OPENSEARCH_JAVA_OPTS:--Xms512m -Xmx512m}"
      - "DISABLE_INSTALL_DEMO_CONFIG=true"
      - "DISABLE_SECURITY_PLUGIN=true"
    env_file:
      - .env # Use local .env file
    volumes:
      - opensearch_data:/usr/share/opensearch/data
    restart: "always"
    ulimits:
      memlock:
        soft: -1
        hard: -1
  ollama:
    image: ollama/ollama:0.5.11
    # platform: linux/amd64  # Removed for Intel Mac compatibility
    labels:
      kompose.service.type: ClusterIP
      kompose.volume.size: 5Gi
    ports:
      - 11434:11434
    environment:
      - OLLAMA_KEEP_ALIVE=24h
    volumes:
      - ollama_data:/root/.ollama
    restart: "always"

  qdrant:
    image: qdrant/qdrant:v1.12.1
    labels:
      kompose.service.type: ClusterIP
      kompose.volume.size: 2Gi
    ports:
      - 6333:6333 # HTTP API
      - 6334:6334 # gRPC API
    environment:
      - QDRANT__STORAGE__STORAGE_PATH=/qdrant/storage
      - QDRANT__LOG_LEVEL=INFO
    volumes:
      - qdrant_data:/qdrant/storage
    restart: "always"

  ragas-evaluator:
    image: ragas-evaluator:latest
    labels:
      kompose.service.type: ClusterIP
    ports:
      - 8002:8000  # RAGAS evaluator API (external:internal)
    environment:
      # Use Stanford AI API for LLM, Ollama for embeddings
      - "OPENAI_API_KEY=${STANFORD_API_KEY}"
      - "OPENAI_BASE_URL=${STANFORD_BASE_URL}"
      - "DEFAULT_MODEL=gpt-4.omini"
      - "ALTERNATIVE_MODELS=claude-3-7-sonnet,deepseek-r1,gpt-4,o1"
      - "DEFAULT_EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2"
      - "EMBEDDING_PROVIDER=ollama"
      - "OLLAMA_BASE_URL=http://ollama:11434"
      - "EMBEDDING_MODEL=nomic-embed-text:latest"
      - "BATCH_SIZE=10"
      - "MAX_WORKERS=4"
      - "LOG_LEVEL=INFO"
    env_file:
      - .env # Use local .env file
    volumes:
      - ragas_config:/app/config
    restart: "always"
    depends_on:
      - ollama
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  ouragboros:
    build: .
    image: ouragboros:local # Local image tag
    labels:
      kompose.service.expose: "true"
      kompose.volume.size: 3Gi
    ports:
      - 8501:8501
      - 8001:8001
    environment:
      # Loaded from .env
      #
      - "OLLAMA_BASE_URL=${OLLAMA_BASE_URL}"
      - "OLLAMA_MODEL_DEFAULT=${OLLAMA_MODEL_DEFAULT}"
      - "SENTENCE_TRANSFORMERS_HOME=${SENTENCE_TRANSFORMERS_HOME}"
      - "PDF_PARSER_MODEL=${PDF_PARSER_MODEL}"
      - "OPENSEARCH_BASE_URL=${OPENSEARCH_BASE_URL}"
      - "OPENSEARCH_INDEX_PREFIX=${OPENSEARCH_INDEX_PREFIX}"
      - "PREFER_OPENSEARCH=${PREFER_OPENSEARCH}"
      # Qdrant configuration
      - "QDRANT_BASE_URL=${QDRANT_BASE_URL}"
      - "PREFER_QDRANT=${PREFER_QDRANT}"
      - "HUGGINGFACE_EMBEDDING_MODEL_DEFAULT=${HUGGINGFACE_EMBEDDING_MODEL_DEFAULT}"
      - "HUGGINGFACE_FINETUNED_EMBEDDING_MODEL=${HUGGINGFACE_FINETUNED_EMBEDDING_MODEL}"
      - "OPENAI_API_KEY=${OPENAI_API_KEY}"
      - "GOOGLE_API_KEY=${GOOGLE_API_KEY}"
      - "STANFORD_API_KEY=${STANFORD_API_KEY}"
      - "STANFORD_BASE_URL=${STANFORD_BASE_URL}"
      # Query logging service configuration
      - "RAGAS_BASE_URL=http://ragas-evaluator:8000"
    env_file:
      - .env # Use local .env file
    volumes:
      - ouragboros_models:/app/models
    restart: "always"
    depends_on:
      - ollama
      - opensearch
      - qdrant
      - ragas-evaluator
    develop:
      watch:
        - action: sync
          path: .
          target: /app
          ignore:
            - .venv/
            - data/
            - models/
        - action: rebuild
          path: ./uv.lock

volumes:
  opensearch_data:
  ollama_data:
  qdrant_data:
  ouragboros_models:
  ragas_config:
